{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "import urllib\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from tf_trt_models.detection import download_detection_model, build_detection_graph\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "import paho.mqtt.client as mqtt\n",
    "client=mqtt.Client(\"control1\")\n",
    "client.connect(\"172.18.0.2\", port=1883, keepalive=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download an SSD model for face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/yeephycho/tensorflow-face-detection\n",
    "FROZEN_GRAPH_NAME = 'data/frozen_inference_graph_face.pb'\n",
    "!wget https://github.com/yeephycho/tensorflow-face-detection/blob/master/model/frozen_inference_graph_face.pb?raw=true -O {FROZEN_GRAPH_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download an image with some faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the frozen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=''\n",
    "frozen_graph = tf.GraphDef()\n",
    "with open(os.path.join(output_dir, FROZEN_GRAPH_NAME), 'rb') as f:\n",
    "  frozen_graph.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few magical constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/NVIDIA-AI-IOT/tf_trt_models/blob/master/tf_trt_models/detection.py\n",
    "INPUT_NAME='image_tensor'\n",
    "BOXES_NAME='detection_boxes'\n",
    "CLASSES_NAME='detection_classes'\n",
    "SCORES_NAME='detection_scores'\n",
    "MASKS_NAME='detection_masks'\n",
    "NUM_DETECTIONS_NAME='num_detections'\n",
    "\n",
    "input_names = [INPUT_NAME]\n",
    "output_names = [BOXES_NAME, CLASSES_NAME, SCORES_NAME, NUM_DETECTIONS_NAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the frozen graph using TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_graph = trt.create_inference_graph(\n",
    "    input_graph_def=frozen_graph,\n",
    "    outputs=output_names,\n",
    "    max_batch_size=1,\n",
    "    max_workspace_size_bytes=1 << 25,\n",
    "    precision_mode='FP16',\n",
    "    minimum_segment_size=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create session and load graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "\n",
    "tf_sess = tf.Session(config=tf_config)\n",
    "\n",
    "# use this if you want to try on the optimized TensorRT graph\n",
    "# Note that this will take a while\n",
    "# tf.import_graph_def(trt_graph, name='')\n",
    "\n",
    "# use this if you want to try directly on the frozen TF graph\n",
    "# this is much faster\n",
    "tf.import_graph_def(frozen_graph, name='')\n",
    "\n",
    "tf_input = tf_sess.graph.get_tensor_by_name(input_names[0] + ':0')\n",
    "tf_scores = tf_sess.graph.get_tensor_by_name('detection_scores:0')\n",
    "tf_boxes = tf_sess.graph.get_tensor_by_name('detection_boxes:0')\n",
    "tf_classes = tf_sess.graph.get_tensor_by_name('detection_classes:0')\n",
    "tf_num_detections = tf_sess.graph.get_tensor_by_name('num_detections:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple try\n",
    "#cap = cv.VideoCapture(\"nvarguscamerasrc ! video/x-raw(memory:NVMM), width=(int)1920, height=(int)1080,format=(string)NV12, framerate=(fraction)30/1 ! nvvidconv ! video/x-raw, format=(string)BGRx ! videoconvert ! video/x-raw, format=(string)BGR ! appsink\")\n",
    "\n",
    "cap = cv.VideoCapture(1)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image = np.array(frame)\n",
    "    \n",
    "    scores, boxes, classes, num_detections = tf_sess.run([tf_scores, tf_boxes, tf_classes, tf_num_detections], feed_dict={tf_input: image[None, ...]})\n",
    "    #boxes = tf_sess.run(tf_boxes,  feed_dict={tf_input: image[None, ...]})\n",
    "    \n",
    "    boxes = boxes[0] # index by 0 to remove batch dimension\n",
    "    scores = scores[0]\n",
    "    classes = classes[0]\n",
    "    num_detections = num_detections[0]\n",
    "    \n",
    "    DETECTION_THRESHOLD = 0.5\n",
    "    \n",
    "    for i in range(int(num_detections)):\n",
    "        if scores[i] < DETECTION_THRESHOLD:\n",
    "            continue\n",
    "        # scale box to image coordinates\n",
    "        box = boxes[i] * np.array([image.shape[0], image.shape[1], image.shape[0], image.shape[1]])\n",
    "        print(\"box:\",box,int(box[0]),int(box[1]),int(box[2]),int(box[3]))\n",
    "        # display rectangle\n",
    "        cv.rectangle(image,(int(box[1]), int(box[0])),  (int(box[3]), int(box[2])),\n",
    "                     (0,255,0),3)\n",
    "        \n",
    "        #roi_gray = image[int(box[0]):(int(box[0])+(int(box[2]) - int(box[0]))),(int(box[3])):(int(box[3]) - int(box[1]))]\n",
    "        \n",
    "        #patch = patches.Rectangle((box[1], box[0]), box[3] - box[1], box[2] - box[0], color='g', alpha=0.3)\n",
    "        #ax.add_patch(patch)\n",
    "\n",
    "        # display class index and score\n",
    "        #plt.text(x=box[1] + 10, y=box[2] - 10, s='%d (%0.2f) ' % (classes[i], scores[i]), color='w')\n",
    "    \n",
    "    cv.imshow('frame',image)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close session to release resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
